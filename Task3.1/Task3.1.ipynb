{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e9cee2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6, \n",
    "                 regularization=None, lambda_reg=0.01):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        Parameters:\n",
    "        - learning_rate: the step size for learning in gradient descent\n",
    "        - max_iterations: Maximum number of training iterations\n",
    "        - tolerance: Convergence threshold for cost function (where to say that the model has converged)\n",
    "        - regularization: Type of regularization ('l1' reduce parameters, 'l2' makes weights smaller ,  or None)\n",
    "        - lambda_reg: Regularization strength (how much it affects the model )\n",
    "        \n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        self.regularization = regularization\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.cost_history = [] # to track the cost function value over iterations\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        σ(z) = 1 / (1 + e^(-z))\n",
    "        \"\"\"\n",
    "        # Clip z to prevent overflow\n",
    "        z = np.clip(z, -250, 250)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def compute_cost(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        J(θ) = -1/m * Σ[y*log(h) + (1-y)*log(1-h)] + regularization_term\n",
    "        \"\"\"\n",
    "        m = len(y_true)\n",
    "        # Add small epsilon to prevent log(0) errors\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        \n",
    "        # Base logistic loss\n",
    "        logistic_cost = -1/m * np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        \n",
    "        # Add regularization term\n",
    "        regularization_cost = 0\n",
    "        #Depends on regularization type\n",
    "        if self.regularization == 'l1':\n",
    "            # L1 regularization: λ * Σ|w_i|\n",
    "            regularization_cost = self.lambda_reg * np.sum(np.abs(self.weights))\n",
    "        elif self.regularization == 'l2':\n",
    "            # L2 regularization: λ * Σw_i²\n",
    "            regularization_cost = self.lambda_reg * np.sum(self.weights ** 2)\n",
    "\n",
    "        #combine both costs\n",
    "        total_cost = logistic_cost + regularization_cost\n",
    "        return total_cost\n",
    "\n",
    "    #compute the regularization itself\n",
    "    def compute_regularization_gradients(self):\n",
    "       \n",
    "        if self.regularization == 'l1':\n",
    "            # L1: λ * sign(w)\n",
    "            return self.lambda_reg * np.sign(self.weights)\n",
    "        elif self.regularization == 'l2':\n",
    "            # L2: 2λ * w\n",
    "            return 2 * self.lambda_reg * self.weights\n",
    "        else:\n",
    "            return np.zeros_like(self.weights)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "       \n",
    "        # Initialize parameters\n",
    "        m, n = X.shape\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "        self.cost_history = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Gradient descent\n",
    "        for i in range(self.max_iterations):\n",
    "            # Forward pass\n",
    "            z = X.dot(self.weights) + self.bias\n",
    "            y_pred = self.sigmoid(z)\n",
    "            \n",
    "            # Compute cost (includes regularization)\n",
    "            cost = self.compute_cost(y, y_pred)\n",
    "            self.cost_history.append(cost)\n",
    "            \n",
    "            # Compute base gradients\n",
    "            dw = (1/m) * X.T.dot(y_pred - y)\n",
    "            db = (1/m) * np.sum(y_pred - y)\n",
    "            \n",
    "            # Add regularization gradients to weight gradients\n",
    "            # no regularization for bias \n",
    "            if self.regularization:\n",
    "                dw += self.compute_regularization_gradients()\n",
    "                \n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "            # Check for convergence if exceeded tolerance\n",
    "            if i > 0 and abs(self.cost_history[-2] - self.cost_history[-1]) < self.tolerance:\n",
    "                print(f\"Converged after {i+1} iterations\")\n",
    "                break\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities\n",
    "        \"\"\"\n",
    "        z = X.dot(self.weights) + self.bias\n",
    "        return self.sigmoid(z)\n",
    "    # low threshold for spam detection to avoid important mails classified as spam\n",
    "    def predict(self, X, threshold=0.3):  \n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        \"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities >= threshold).astype(int)\n",
    "    def classification_report(self, X, y, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Compute precision, recall, and F1-score from scratch.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X, threshold)\n",
    "         # first matrix to help with the classification report \n",
    "        TP = FP = TN = FN = 0\n",
    "        for true, pred in zip(y, predictions):\n",
    "            if true == 1 and pred == 1:\n",
    "           \n",
    "                TP += 1\n",
    "            elif true == 0 and pred == 0:\n",
    "                TN += 1\n",
    "            elif true == 0 and pred == 1:\n",
    "                FP += 1\n",
    "            elif true == 1 and pred == 0:\n",
    "                FN += 1\n",
    "\n",
    "    # Avoid division by zero\n",
    "    #model accuracy to check overall performance\n",
    "        accuracy = (TP + TN) / len(y)\n",
    "        # precision to check for false positives\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        # recall to check for false negatives\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        # f1 score to check balance between precision and recall\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "\n",
    "        }\n",
    "\n",
    "    # a function to print the classification report\n",
    "    def score(self, X, y):\n",
    "\n",
    "        scorep= self.classification_report(X, y)\n",
    "\n",
    "        print(\"Accuracy\" , scorep['accuracy'])\n",
    "        print(\"Precision\" , scorep['precision'] )\n",
    "        print(\"Recall\" , scorep['recall'])\n",
    "        print(\"F1 Score\" , scorep['f1_score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bf529",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9f98dd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>num_links</th>\n",
       "      <th>num_words</th>\n",
       "      <th>has_offer</th>\n",
       "      <th>sender_score</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583621</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   message_id  num_links  num_words  has_offer  sender_score  all_caps  \\\n",
       "0           1          3         98          1      0.718607         0   \n",
       "1           2          0        170          0      0.698901         1   \n",
       "2           3          0         38          0      0.620466         0   \n",
       "3           4          0        116          0      0.701755         0   \n",
       "4           5          3         89          1      0.583621         1   \n",
       "\n",
       "   is_spam  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(r\"D:\\Downloads\\MIA\\Task3\\f1-spam-detection\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31994d8a",
   "metadata": {},
   "source": [
    "## From EDA we find no needing for cleaning as our Data has no dublictes or nulls \n",
    "also we find that the data is imbalanced \n",
    "also there is correlation between num of links, has offer and out target (spam) so it`s better to use f1 score rather than accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "bc3891a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871e4f653b504f54b132ed729ef6db29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 201.54it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467d547bee934ce7b18d454046c90b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c655c5018c444bf6bf3cecbcb9dccfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67642c1cb7cf47bd9808ae695f19a784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "profile=ProfileReport(df, title = \"EDA Report\", explorative=True)\n",
    "\n",
    "profile.to_file(\"eda_reportC1.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa800e",
   "metadata": {},
   "source": [
    "split target from needed cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2af92a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df[['num_links', 'has_offer', 'num_words', 'all_caps','sender_score']]\n",
    "y= df['is_spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e51a36",
   "metadata": {},
   "source": [
    "split to train , test , validate \n",
    "better validate to fine tune the paramters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9fcfca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f, x_test, y_f, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_f, y_f, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b3da560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to make sure there won`t be any error ` \n",
    "# Scale only features \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daebbb51",
   "metadata": {},
   "source": [
    "## Hyperparameter Search  by a loop to see which paramters are better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b040df",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "max_iterations_list = [500, 1000]\n",
    "regularizations = [None, \"l1\", \"l2\" ]\n",
    "lambda_regs = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "selection_metric = 'f1_score'  # Good for spam detection\n",
    "best_val_metric = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for max_iterations in max_iterations_list:\n",
    "        for regularization in regularizations:\n",
    "            for lambda_reg in lambda_regs if regularization else [None]:\n",
    "\n",
    "                model = LogisticRegression(\n",
    "                    learning_rate=learning_rate,\n",
    "                    max_iterations=max_iterations,\n",
    "                    regularization=regularization,\n",
    "                    lambda_reg=lambda_reg if lambda_reg is not None else 0.01\n",
    "                )\n",
    "                model.fit(x_train_scaled, y_train)\n",
    "\n",
    "                y_val_pred = model.predict(x_val_scaled)\n",
    "\n",
    "                # Use accuracy for model selection\n",
    "                report = model.classification_report(x_val_scaled, y_val)\n",
    "                val_metric = report[selection_metric]\n",
    "\n",
    "                if val_metric > best_val_metric:\n",
    "                    best_val_metric = val_metric\n",
    "                    best_model = model\n",
    "                    best_params = {\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'max_iterations': max_iterations,\n",
    "                        'regularization': regularization,\n",
    "                        'lambda_reg': lambda_reg\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "20d7b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 403 iterations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model.fit(x_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7e33218c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9437990837696335,\n",
       " 'precision': 0.773224043715847,\n",
       " 'recall': 0.5206991720331187,\n",
       " 'f1_score': 0.622319956019791}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.classification_report(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f0a62045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9358638743455497,\n",
       " 'precision': 0.780373831775701,\n",
       " 'recall': 0.5284810126582279,\n",
       " 'f1_score': 0.6301886792452831}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.classification_report(x_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "06cac7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9450261780104712,\n",
       " 'precision': 0.821256038647343,\n",
       " 'recall': 0.4956268221574344,\n",
       " 'f1_score': 0.6181818181818183}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.classification_report(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9caf8ce",
   "metadata": {},
   "source": [
    "## Load and use model on test file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= pd.read_csv(r\"D:\\Downloads\\MIA\\Task3\\f1-spam-detection\\test.csv\")\n",
    "x_test = df_test[['num_links', 'has_offer', 'num_words', 'all_caps', 'sender_score']]\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "y_test_pred = best_model.predict(x_test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"message_id\": df_test[\"message_id\"],\n",
    "    \"is_spam\": y_test_pred\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
